{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['lgbm', 'catboost', 'xgboost']\n",
    "valids = [pd.read_csv(f\"output/{p}_valid.csv\") for p in prefixes]\n",
    "submissions = [pd.read_csv(f\"output/{p}.csv\") for p in prefixes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    p_lgbm = trial.suggest_uniform('lgbm', 0.0, 1.0)\n",
    "    p_cat = trial.suggest_uniform('cat', 0.0, 1.0)\n",
    "    p_xgb = trial.suggest_uniform('xgb', 0.0, 1.0)\n",
    "    y = valids[0]['rating'].values\n",
    "    a_lgbm = valids[0].drop('rating', axis=1).values\n",
    "    a_cat = valids[1].drop('rating', axis=1).values\n",
    "    a_xgb = valids[2].drop('rating', axis=1).values\n",
    "    a = p_lgbm * a_lgbm + p_cat * a_cat + p_xgb * a_xgb\n",
    "    b = np.argmax(a, axis=1)\n",
    "\n",
    "    return f1_score(y, b, average='micro')\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(by='value', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lgbm = study.best_params['lgbm']\n",
    "p_cat = study.best_params['cat']\n",
    "p_xgb = study.best_params['xgb']\n",
    "\n",
    "a_lgbm = submissions[0].drop(['id', 'rating'], axis=1).values\n",
    "a_cat = submissions[1].drop(['id', 'rating'], axis=1).values\n",
    "a = p_lgbm * a_lgbm + p_cat * a_cat\n",
    "\n",
    "sub = submissions[0][['id']].reset_index(drop=True)\n",
    "sub['rating'] = a.argmax(axis=1) + 1\n",
    "sub.to_csv('blend_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = valids[0].drop('rating', axis=1)\n",
    "a = a.rename(columns={col: f'{col}_0' for col in a.columns})\n",
    "b = valids[1].drop('rating', axis=1)\n",
    "b = b.rename(columns={col: f'{col}_1' for col in b.columns})\n",
    "c = valids[2].drop('rating', axis=1)\n",
    "c = c.rename(columns={col: f'{col}_2' for col in c.columns})\n",
    "\n",
    "mgd_val = pd.concat([a, b, c], axis=1)\n",
    "mgd_val['rating'] = valids[0]['rating']\n",
    "\n",
    "a = submissions[0].drop(['id', 'rating'], axis=1)\n",
    "a = a.rename(columns={col: f'{col}_0' for col in a.columns})\n",
    "b = submissions[1].drop(['id', 'rating'], axis=1)\n",
    "b = b.rename(columns={col: f'{col}_1' for col in b.columns})\n",
    "c = submissions[2].drop(['id', 'rating'], axis=1)\n",
    "c = c.rename(columns={col: f'{col}_2' for col in c.columns})\n",
    "\n",
    "mgd_sub = pd.concat([a, b, c], axis=1)\n",
    "mgd_sub['id'] = submissions[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mgd_val.drop('rating', axis=1)\n",
    "y_train = mgd_val['rating']\n",
    "\n",
    "X = mgd_sub.drop('id', axis=1)\n",
    "\n",
    "params = {\n",
    "    \"iterations\": 2000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"loss_function\": 'MultiClass',\n",
    "}\n",
    "\n",
    "train_dataset = Pool(data=X_train, label=y_train)\n",
    "test_dataset = Pool(data=X)\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_dataset)\n",
    "y = model.predict_proba(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = mgd_sub[['id']].reset_index(drop=True)\n",
    "sub['rating'] = y.argmax(axis=1) + 1\n",
    "assert sub['rating'].min() == 1 and sub['rating'].max() == 10\n",
    "sub.to_csv('stack_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = valids[0].drop('rating', axis=1)\n",
    "a = a.rename(columns={col: f'{col}_0' for col in a.columns})\n",
    "b = valids[1].drop('rating', axis=1)\n",
    "b = b.rename(columns={col: f'{col}_1' for col in b.columns})\n",
    "c = valids[2].drop('rating', axis=1)\n",
    "c = c.rename(columns={col: f'{col}_2' for col in c.columns})\n",
    "\n",
    "mgd_val = pd.concat([a, b, c], axis=1)\n",
    "mgd_val['rating'] = valids[0]['rating']\n",
    "\n",
    "a = submissions[0].drop(['id', 'rating'], axis=1)\n",
    "a = a.rename(columns={col: f'{col}_0' for col in a.columns})\n",
    "b = submissions[1].drop(['id', 'rating'], axis=1)\n",
    "b = b.rename(columns={col: f'{col}_1' for col in b.columns})\n",
    "c = submissions[2].drop(['id', 'rating'], axis=1)\n",
    "c = c.rename(columns={col: f'{col}_2' for col in c.columns})\n",
    "\n",
    "mgd_sub = pd.concat([a, b, c], axis=1)\n",
    "mgd_sub['id'] = submissions[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "books = pd.read_csv('input/transformed/books.csv', usecols=['book_idx', 'title_idx', 'author_idx', 'publisher_idx'])\n",
    "users = pd.read_csv('input/transformed/users.csv', usecols=['user_idx', 'age', 'city_idx', 'province_idx', 'country_idx'])\n",
    "train_ratings = pd.read_csv('input/transformed/train_ratings.csv', usecols=['id', 'user_idx', 'book_idx', 'rating'])\n",
    "test_ratings = pd.read_csv('input/transformed/test_ratings.csv', usecols=['id', 'user_idx', 'book_idx'])\n",
    "\n",
    "train = train_ratings.merge(users, on=['user_idx']).merge(books, on=['book_idx']).sort_values(by='id').drop('id', axis=1)\n",
    "train['rating'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "X, y = train.drop('rating', axis=1), train['rating']\n",
    "\n",
    "validations = []\n",
    "\n",
    "for fold_idx, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    validations.append(\n",
    "        X_test[['book_idx', 'user_idx', 'title_idx', 'author_idx', 'publisher_idx', 'age', 'city_idx', 'province_idx', 'country_idx']].reset_index(drop=True)\n",
    "    )\n",
    "validations = pd.concat(validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings = pd.read_csv('input/transformed/test_ratings.csv', usecols=['id', 'user_idx', 'book_idx'])\n",
    "test = test_ratings.merge(users, on=['user_idx']).merge(books, on=['book_idx'])[['book_idx', 'user_idx', 'title_idx', 'author_idx', 'publisher_idx', 'age', 'city_idx', 'province_idx', 'country_idx']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['city_idx', 'province_idx', 'country_idx']:\n",
    "    validations[c] = validations[c].fillna(-1).astype(int)\n",
    "    test[c] = test[c].fillna(-1).astype(int)\n",
    "for c in ['author_idx', 'publisher_idx']:\n",
    "    validations[c] = validations[c].fillna(-1).astype(int)\n",
    "    test[c] = test[c].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd_val = mgd_val.reset_index(drop=True)\n",
    "validations = validations.reset_index(drop=True)\n",
    "\n",
    "mgd_val = pd.concat([mgd_val, validations], axis=1)\n",
    "mgd_sub = pd.concat([mgd_sub, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mgd_val.drop('rating', axis=1)\n",
    "y_train = mgd_val['rating']\n",
    "\n",
    "X = mgd_sub.drop('id', axis=1)\n",
    "\n",
    "params = {\n",
    "    \"iterations\": 2000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"loss_function\": 'MultiClass',\n",
    "}\n",
    "\n",
    "train_dataset = Pool(data=X_train, label=y_train)\n",
    "test_dataset = Pool(data=X)\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_dataset)\n",
    "y = model.predict_proba(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = mgd_sub[['id']].reset_index(drop=True)\n",
    "sub['rating'] = y.argmax(axis=1) + 1\n",
    "assert sub['rating'].min() == 1 and sub['rating'].max() == 10\n",
    "sub.to_csv('stackv2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c89b5301ada1d96cd3523f144e4a3cd3ad36f6698a61e6b8277fb627756a86c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
